{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "statistics learning project 2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Import necessary libraries for ML and Pre-Processing"
      ],
      "metadata": {
        "id": "3zYw3uDFXNjT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pV71FbhbMBZu",
        "outputId": "12e4895a-f8ed-4dc4-9ede-9e9cd6312e49"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: feature-engine in /usr/local/lib/python3.7/dist-packages (1.2.0)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from feature-engine) (1.4.1)\n",
            "Requirement already satisfied: pandas>=1.0.3 in /usr/local/lib/python3.7/dist-packages (from feature-engine) (1.1.5)\n",
            "Requirement already satisfied: numpy>=1.18.2 in /usr/local/lib/python3.7/dist-packages (from feature-engine) (1.19.5)\n",
            "Requirement already satisfied: statsmodels>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from feature-engine) (0.13.1)\n",
            "Requirement already satisfied: scikit-learn>=0.22.2 in /usr/local/lib/python3.7/dist-packages (from feature-engine) (1.0.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.0.3->feature-engine) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.0.3->feature-engine) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=1.0.3->feature-engine) (1.15.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.22.2->feature-engine) (3.0.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.22.2->feature-engine) (1.1.0)\n",
            "Requirement already satisfied: patsy>=0.5.2 in /usr/local/lib/python3.7/dist-packages (from statsmodels>=0.11.1->feature-engine) (0.5.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install feature-engine #Library for random sample imputer\n",
        "from feature_engine.imputation import RandomSampleImputer\n",
        "\n",
        "#Importing the necessary libraries for EDA and model building\n",
        "import numpy as np \n",
        "import pandas as pd \n",
        "from sklearn import preprocessing\n",
        "import matplotlib.pyplot as plt \n",
        "import seaborn as sns\n",
        "import warnings\n",
        "import time\n",
        "warnings.simplefilter(action='ignore')\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#importing ML models from sklearn library\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "#Importing metrics functions from SK Learn\n",
        "from sklearn.metrics import roc_auc_score, r2_score, mean_absolute_error, mean_squared_error\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn import metrics\n",
        "from pprint import pprint\n",
        "\n",
        "# # Used for Downloading MNIST\n",
        "# from sklearn.datasets import fetch_mldata\n",
        "\n",
        "# Used for Splitting Training and Test Sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing the dataset"
      ],
      "metadata": {
        "id": "N5oKQLSqXbo6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = pd.read_csv('https://gist.githubusercontent.com/PUUDI/861771ffca8462507b487b6f75f2386d/raw/44e4760f1f6ee628c9674fe1c87e63bd4fbcf19d/gistfile1.txt')"
      ],
      "metadata": {
        "id": "72ybHOk3XY8M"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "preparing the data for classification"
      ],
      "metadata": {
        "id": "7I_aOGJZXpqr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#dropping the converted Group data points\n",
        "classes = ['Nondemented', 'Demented']\n",
        "dataset.drop(dataset.loc[dataset['Group'] == 'Converted'].index, inplace=True) # dataset.Group[dataset.Group == 'Converted'] = 'Nondemented' \n",
        "\n",
        "#Dropping the unwanted columns that won't be needing to include in our model\n",
        "dataset.drop(['Subject ID', 'MRI ID', 'Hand','CDR','MR Delay','Visit'], axis=1, inplace=True) # 'MR Delay''Visit','Age','EDUC','eTIV'\n",
        "\n",
        "#Encoding binary variables\n",
        "dataset['M/F'] = dataset['M/F'].apply(lambda x: ['M', 'F'].index(x))\n",
        "\n",
        "#Encoding the class variable\n",
        "dataset['Class'] = [classes.index(group) for group in dataset['Group']]"
      ],
      "metadata": {
        "id": "oFWE36bUXebd"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Imputing missing values using Random Sample technique"
      ],
      "metadata": {
        "id": "GwwkFMr7X38e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from feature_engine.imputation import RandomSampleImputer\n",
        "\n",
        "imputer = RandomSampleImputer(\n",
        "        random_state=['SES','MMSE'],\n",
        "        seed='observation',\n",
        "        seeding_method='add'\n",
        "    )\n",
        "\n",
        "# fit the imputer\n",
        "imputer.fit(dataset)\n",
        "\n",
        "dataset = imputer.transform(dataset)"
      ],
      "metadata": {
        "id": "StfoHE7xX1FO"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "-zFtaoRvY5Bj",
        "outputId": "36d7572c-4609-4c55-ad66-0170668bc204"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-e3033111-0ee4-4082-a0aa-b407a0aeb113\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Group</th>\n",
              "      <th>M/F</th>\n",
              "      <th>Age</th>\n",
              "      <th>EDUC</th>\n",
              "      <th>SES</th>\n",
              "      <th>MMSE</th>\n",
              "      <th>eTIV</th>\n",
              "      <th>nWBV</th>\n",
              "      <th>ASF</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Nondemented</td>\n",
              "      <td>0</td>\n",
              "      <td>87</td>\n",
              "      <td>14</td>\n",
              "      <td>2.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>1987</td>\n",
              "      <td>0.696</td>\n",
              "      <td>0.883</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Nondemented</td>\n",
              "      <td>0</td>\n",
              "      <td>88</td>\n",
              "      <td>14</td>\n",
              "      <td>2.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>2004</td>\n",
              "      <td>0.681</td>\n",
              "      <td>0.876</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Demented</td>\n",
              "      <td>0</td>\n",
              "      <td>75</td>\n",
              "      <td>12</td>\n",
              "      <td>1.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>1678</td>\n",
              "      <td>0.736</td>\n",
              "      <td>1.046</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Demented</td>\n",
              "      <td>0</td>\n",
              "      <td>76</td>\n",
              "      <td>12</td>\n",
              "      <td>2.0</td>\n",
              "      <td>28.0</td>\n",
              "      <td>1738</td>\n",
              "      <td>0.713</td>\n",
              "      <td>1.010</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Demented</td>\n",
              "      <td>0</td>\n",
              "      <td>80</td>\n",
              "      <td>12</td>\n",
              "      <td>2.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1698</td>\n",
              "      <td>0.701</td>\n",
              "      <td>1.034</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>368</th>\n",
              "      <td>Demented</td>\n",
              "      <td>0</td>\n",
              "      <td>82</td>\n",
              "      <td>16</td>\n",
              "      <td>1.0</td>\n",
              "      <td>28.0</td>\n",
              "      <td>1693</td>\n",
              "      <td>0.694</td>\n",
              "      <td>1.037</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>369</th>\n",
              "      <td>Demented</td>\n",
              "      <td>0</td>\n",
              "      <td>86</td>\n",
              "      <td>16</td>\n",
              "      <td>1.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>1688</td>\n",
              "      <td>0.675</td>\n",
              "      <td>1.040</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>370</th>\n",
              "      <td>Nondemented</td>\n",
              "      <td>1</td>\n",
              "      <td>61</td>\n",
              "      <td>13</td>\n",
              "      <td>2.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>1319</td>\n",
              "      <td>0.801</td>\n",
              "      <td>1.331</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>371</th>\n",
              "      <td>Nondemented</td>\n",
              "      <td>1</td>\n",
              "      <td>63</td>\n",
              "      <td>13</td>\n",
              "      <td>2.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>1327</td>\n",
              "      <td>0.796</td>\n",
              "      <td>1.323</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>372</th>\n",
              "      <td>Nondemented</td>\n",
              "      <td>1</td>\n",
              "      <td>65</td>\n",
              "      <td>13</td>\n",
              "      <td>2.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>1333</td>\n",
              "      <td>0.801</td>\n",
              "      <td>1.317</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>336 rows Ã— 10 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e3033111-0ee4-4082-a0aa-b407a0aeb113')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e3033111-0ee4-4082-a0aa-b407a0aeb113 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e3033111-0ee4-4082-a0aa-b407a0aeb113');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "           Group  M/F  Age  EDUC  SES  MMSE  eTIV   nWBV    ASF  Class\n",
              "0    Nondemented    0   87    14  2.0  27.0  1987  0.696  0.883      0\n",
              "1    Nondemented    0   88    14  2.0  30.0  2004  0.681  0.876      0\n",
              "2       Demented    0   75    12  1.0  23.0  1678  0.736  1.046      1\n",
              "3       Demented    0   76    12  2.0  28.0  1738  0.713  1.010      1\n",
              "4       Demented    0   80    12  2.0  22.0  1698  0.701  1.034      1\n",
              "..           ...  ...  ...   ...  ...   ...   ...    ...    ...    ...\n",
              "368     Demented    0   82    16  1.0  28.0  1693  0.694  1.037      1\n",
              "369     Demented    0   86    16  1.0  26.0  1688  0.675  1.040      1\n",
              "370  Nondemented    1   61    13  2.0  30.0  1319  0.801  1.331      0\n",
              "371  Nondemented    1   63    13  2.0  30.0  1327  0.796  1.323      0\n",
              "372  Nondemented    1   65    13  2.0  30.0  1333  0.801  1.317      0\n",
              "\n",
              "[336 rows x 10 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = dataset.Class\n",
        "dataset.drop(['Group','Class'], axis=1, inplace=True) # 'MR Delay''Visit',\n",
        "X = dataset\n",
        "\n",
        "train_feature, test_feature, train_label, test_label = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "f_p9gFaRX9JD"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fitting model to the dataset with default parameters"
      ],
      "metadata": {
        "id": "43d8RFxAZfYw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nbc = GaussianNB()\n",
        "#Fitting the model\n",
        "nbc.fit(train_feature, train_label)\n",
        "\n",
        "nbc_predict = nbc.predict(test_feature)\n",
        "\n",
        "print(\"=== Confusion Matrix ===\")\n",
        "print(confusion_matrix(test_label, nbc_predict))\n",
        "print('\\n')\n",
        "print(\"=== Classification Report ===\")\n",
        "print(classification_report(test_label, nbc_predict))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y4Q_lE3xZAsi",
        "outputId": "0464db3a-9f39-4714-961f-96285a32d53b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Confusion Matrix ===\n",
            "[[36  2]\n",
            " [ 5 25]]\n",
            "\n",
            "\n",
            "=== Classification Report ===\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.95      0.91        38\n",
            "           1       0.93      0.83      0.88        30\n",
            "\n",
            "    accuracy                           0.90        68\n",
            "   macro avg       0.90      0.89      0.89        68\n",
            "weighted avg       0.90      0.90      0.90        68\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "knn = KNeighborsClassifier()\n",
        "knn.fit(train_feature, train_label)\n",
        "\n",
        "knn_predict = knn.predict(test_feature)\n",
        "\n",
        "print(\"=== Confusion Matrix ===\")\n",
        "print(confusion_matrix(test_label, knn_predict))\n",
        "print('\\n')\n",
        "print(\"=== Classification Report ===\")\n",
        "print(classification_report(test_label, knn_predict))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i61twSB7ZIRS",
        "outputId": "6933f50e-a30c-4b61-dd28-f834e4aa89df"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Confusion Matrix ===\n",
            "[[26 12]\n",
            " [14 16]]\n",
            "\n",
            "\n",
            "=== Classification Report ===\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.65      0.68      0.67        38\n",
            "           1       0.57      0.53      0.55        30\n",
            "\n",
            "    accuracy                           0.62        68\n",
            "   macro avg       0.61      0.61      0.61        68\n",
            "weighted avg       0.62      0.62      0.62        68\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lda = LinearDiscriminantAnalysis()\n",
        "lda.fit(train_feature, train_label)\n",
        "\n",
        "lda_predict = lda.predict(test_feature)\n",
        "\n",
        "print(\"=== Confusion Matrix ===\")\n",
        "print(confusion_matrix(test_label, lda_predict))\n",
        "print('\\n')\n",
        "print(\"=== Classification Report ===\")\n",
        "print(classification_report(test_label, lda_predict))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_K7r6OfXZMfT",
        "outputId": "afa67099-fbab-4113-baf3-0d03fde94e0b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Confusion Matrix ===\n",
            "[[38  0]\n",
            " [ 9 21]]\n",
            "\n",
            "\n",
            "=== Classification Report ===\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      1.00      0.89        38\n",
            "           1       1.00      0.70      0.82        30\n",
            "\n",
            "    accuracy                           0.87        68\n",
            "   macro avg       0.90      0.85      0.86        68\n",
            "weighted avg       0.89      0.87      0.86        68\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "log = LogisticRegression(solver='liblinear')\n",
        "log.fit(train_feature, train_label)\n",
        "\n",
        "log_predict = log.predict(test_feature)\n",
        "\n",
        "print(\"=== Confusion Matrix ===\")\n",
        "print(confusion_matrix(test_label, log_predict))\n",
        "print('\\n')\n",
        "print(\"=== Classification Report ===\")\n",
        "print(classification_report(test_label, log_predict))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gsNFDAU_ZPJ7",
        "outputId": "0de3c151-9000-44fc-ffc4-bcf4ae2f7efe"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Confusion Matrix ===\n",
            "[[37  1]\n",
            " [ 5 25]]\n",
            "\n",
            "\n",
            "=== Classification Report ===\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.97      0.93        38\n",
            "           1       0.96      0.83      0.89        30\n",
            "\n",
            "    accuracy                           0.91        68\n",
            "   macro avg       0.92      0.90      0.91        68\n",
            "weighted avg       0.92      0.91      0.91        68\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "svc = SVC(probability=True)\n",
        "svc.fit(train_feature, train_label)\n",
        "\n",
        "svc_predict = svc.predict(test_feature)\n",
        "\n",
        "print(\"=== Confusion Matrix ===\")\n",
        "print(confusion_matrix(test_label, svc_predict))\n",
        "print('\\n')\n",
        "print(\"=== Classification Report ===\")\n",
        "print(classification_report(test_label, svc_predict))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cUGiI1JaZRYL",
        "outputId": "1fcffa0a-4e15-4b38-d3af-292f4c8836fd"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Confusion Matrix ===\n",
            "[[38  0]\n",
            " [30  0]]\n",
            "\n",
            "\n",
            "=== Classification Report ===\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.56      1.00      0.72        38\n",
            "           1       0.00      0.00      0.00        30\n",
            "\n",
            "    accuracy                           0.56        68\n",
            "   macro avg       0.28      0.50      0.36        68\n",
            "weighted avg       0.31      0.56      0.40        68\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rf = RandomForestClassifier()\n",
        "rf.fit(train_feature, train_label)\n",
        "\n",
        "\n",
        "rf_predict = rf.predict(test_feature)\n",
        "\n",
        "print(\"=== Confusion Matrix ===\")\n",
        "print(confusion_matrix(test_label, rf_predict))\n",
        "print('\\n')\n",
        "print(\"=== Classification Report ===\")\n",
        "print(classification_report(test_label, rf_predict))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5sGfKX9NZUHa",
        "outputId": "d473f751-7165-488d-a3b2-085cf362594b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Confusion Matrix ===\n",
            "[[36  2]\n",
            " [ 2 28]]\n",
            "\n",
            "\n",
            "=== Classification Report ===\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.95      0.95        38\n",
            "           1       0.93      0.93      0.93        30\n",
            "\n",
            "    accuracy                           0.94        68\n",
            "   macro avg       0.94      0.94      0.94        68\n",
            "weighted avg       0.94      0.94      0.94        68\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gb = GradientBoostingClassifier(criterion = \"friedman_mse\")\n",
        "gb.fit(train_feature, train_label)\n",
        "\n",
        "gb_predict = gb.predict(test_feature)\n",
        "\n",
        "print(\"=== Confusion Matrix ===\")\n",
        "print(confusion_matrix(test_label, gb_predict))\n",
        "print('\\n')\n",
        "print(\"=== Classification Report ===\")\n",
        "print(classification_report(test_label, gb_predict))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vqLbD8emZX-q",
        "outputId": "948cbeea-30f2-4df0-d546-92ace8c05d07"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Confusion Matrix ===\n",
            "[[35  3]\n",
            " [ 2 28]]\n",
            "\n",
            "\n",
            "=== Classification Report ===\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.92      0.93        38\n",
            "           1       0.90      0.93      0.92        30\n",
            "\n",
            "    accuracy                           0.93        68\n",
            "   macro avg       0.92      0.93      0.93        68\n",
            "weighted avg       0.93      0.93      0.93        68\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fitting Models with default parameters\n",
        "\n",
        "### Gaussian Naive Bayes  \n",
        "> Default parameters\n",
        "---\n",
        "F1 Score: **0.86**\n",
        "### K Nearest Neighbour Classifier \n",
        "> Default parameters\n",
        "---\n",
        "F1 Score: **0.64**\n",
        "### Linear Discriminant Analysis  \n",
        "> Default parameters\n",
        "---\n",
        "F1 Score: **0.85**\n",
        "### Logistic Regression  \n",
        "> Default parameters\n",
        "---\n",
        "F1 Score: **0.85**\n",
        "\n",
        "### Support Vector Machine \n",
        "> Default parameters\n",
        "---\n",
        "F1 Score: **0.58**\n",
        "\n",
        "### Random Forest Classifier \n",
        "> Default parameters\n",
        "---\n",
        "F1 Score: **0.89**\n",
        "### Gradient Bossting Algorithm \n",
        "> Default parameters\n",
        "---\n",
        "F1 Score: **0.90**\n",
        "\n"
      ],
      "metadata": {
        "id": "3L62f15Janei"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Applying cross validation technique to reduce overfitting and get generalized model scores\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "R3i-pdEMa_Ni"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "models = [RandomForestClassifier(), LogisticRegression(solver='liblinear'),LinearDiscriminantAnalysis(), GradientBoostingClassifier()]\n",
        "names = [\"Random Forest\", \"Logistic Regression\",\"Linear Discriminant Analysis\",\"Gradient Boosting\"]\n",
        "for model, name in zip(models, names):\n",
        "    print(name)\n",
        "    start = time.time()\n",
        "    for score in [\"accuracy\", \"precision\", \"recall\"]:\n",
        "        print(score,\" : \",cross_val_score(model, X, y ,scoring=score, cv=5).mean())\n",
        "       \n",
        "    print('Time elapsed: ',time.time() - start)\n",
        "    print('\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-VbKaEuWbF08",
        "outputId": "c77f1f95-e81c-45c5-e15e-3a382f80f4e6"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest\n",
            "accuracy  :  0.8332309043020192\n",
            "precision  :  0.8454205069124423\n",
            "recall  :  0.7664367816091955\n",
            "Time elapsed:  2.301682233810425\n",
            "\n",
            "\n",
            "Logistic Regression\n",
            "accuracy  :  0.8035557506584723\n",
            "precision  :  0.8376535541752933\n",
            "recall  :  0.6836781609195401\n",
            "Time elapsed:  0.09908485412597656\n",
            "\n",
            "\n",
            "Linear Discriminant Analysis\n",
            "accuracy  :  0.7974100087796312\n",
            "precision  :  0.8669657234874626\n",
            "recall  :  0.6294252873563219\n",
            "Time elapsed:  0.0897073745727539\n",
            "\n",
            "\n",
            "Gradient Boosting\n",
            "accuracy  :  0.8035996488147499\n",
            "precision  :  0.7735261454240201\n",
            "recall  :  0.7873563218390804\n",
            "Time elapsed:  1.251885175704956\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Balancing the data to reduce model bias towards one classification\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "S73fTiFNbMR8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Oversample and plot imbalanced dataset with SMOTE\n",
        "from collections import Counter\n",
        "from sklearn.datasets import make_classification\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from matplotlib import pyplot\n",
        "from numpy import where\n",
        "\n",
        "counter = Counter(y)\n",
        "print(counter)\n",
        "# transform the dataset\n",
        "oversample = SMOTE()\n",
        "X, y = oversample.fit_resample(X, y)\n",
        "# summarize the new class distribution\n",
        "counter = Counter(y)\n",
        "print(counter)\n",
        "\n",
        "train_feature, test_feature, train_label, test_label = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-w3MJ2tfbk6a",
        "outputId": "549bb1d3-2bb4-419c-e7f1-8cb332014cce"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Counter({0: 190, 1: 146})\n",
            "Counter({0: 190, 1: 190})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "models = [RandomForestClassifier(), LogisticRegression(solver='liblinear'),LinearDiscriminantAnalysis(), GradientBoostingClassifier()]\n",
        "names = [\"Random Forest\", \"Logistic Regression\",\"Linear Discriminant Analysis\",\"Gradient Boosting\"]\n",
        "for model, name in zip(models, names):\n",
        "    print(name)\n",
        "    start = time.time()\n",
        "    for score in [\"accuracy\", \"precision\", \"recall\"]:\n",
        "        print(score,\" : \",cross_val_score(model, X, y ,scoring=score, cv=5).mean())\n",
        "       \n",
        "    print('Time elapsed: ',time.time() - start)\n",
        "    print('\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G-qykKbTb5jJ",
        "outputId": "cce3613f-3d2d-4906-ea22-c67b7e28b00d"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest\n",
            "accuracy  :  0.8631578947368421\n",
            "precision  :  0.871100517129929\n",
            "recall  :  0.8631578947368421\n",
            "Time elapsed:  2.2818374633789062\n",
            "\n",
            "\n",
            "Logistic Regression\n",
            "accuracy  :  0.805263157894737\n",
            "precision  :  0.844797356011749\n",
            "recall  :  0.7526315789473685\n",
            "Time elapsed:  0.11090278625488281\n",
            "\n",
            "\n",
            "Linear Discriminant Analysis\n",
            "accuracy  :  0.8236842105263158\n",
            "precision  :  0.8816535534207948\n",
            "recall  :  0.7473684210526316\n",
            "Time elapsed:  0.09803080558776855\n",
            "\n",
            "\n",
            "Gradient Boosting\n",
            "accuracy  :  0.8421052631578947\n",
            "precision  :  0.8313056332144348\n",
            "recall  :  0.8315789473684211\n",
            "Time elapsed:  1.3309507369995117\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Applying Randomized Gride Search CV to find best parameters for the models"
      ],
      "metadata": {
        "id": "e9BAKqBFcNpp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Grid Search CV for Random Forest"
      ],
      "metadata": {
        "id": "OM8uT_7ScxwJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "# Number of estimators in random forest\n",
        "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
        "# Number of features to consider at every split\n",
        "max_features = ['auto', 'sqrt']\n",
        "# Maximum number of levels in tree\n",
        "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
        "max_depth.append(None)\n",
        "# Minimum number of samples required to split a node\n",
        "min_samples_split = [2, 5, 10]\n",
        "# Minimum number of samples required at each leaf node\n",
        "min_samples_leaf = [1, 2, 4]\n",
        "# Method of selecting samples for training each tree\n",
        "bootstrap = [True, False]\n",
        "\n",
        "# Create the random grid\n",
        "random_grid = {'n_estimators': n_estimators,\n",
        "               'max_features': max_features,\n",
        "               'max_depth': max_depth,\n",
        "               'min_samples_split': min_samples_split,\n",
        "               'min_samples_leaf': min_samples_leaf,\n",
        "               'bootstrap': bootstrap}\n",
        "\n",
        "pprint(random_grid)\n",
        "\n",
        "# Use the random grid to search for best hyperparameters\n",
        "# First create the base model to tune\n",
        "rf = RandomForestClassifier(random_state = 42)\n",
        "# Random search of parameters, using 3 fold cross validation, \n",
        "# search across 100 different combinations, and use all available cores\n",
        "start = time.time()\n",
        "rf_random = RandomizedSearchCV(estimator=rf, param_distributions=random_grid,\n",
        "                              n_iter = 10, scoring='neg_mean_absolute_error', \n",
        "                              cv = 3, verbose=2, random_state=42, n_jobs=-1,\n",
        "                              return_train_score=True)\n",
        "\n",
        "# Fit the random search model\n",
        "rf_random.fit(train_feature, train_label);\n",
        "print('Time elapsed: ',time.time() - start)\n",
        "\n",
        "print('\\n')\n",
        "pprint(rf_random.best_params_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WfsdK5TLcGoa",
        "outputId": "5bd0544f-c462-4cde-8d31-febea9014663"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'bootstrap': [True, False],\n",
            " 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, None],\n",
            " 'max_features': ['auto', 'sqrt'],\n",
            " 'min_samples_leaf': [1, 2, 4],\n",
            " 'min_samples_split': [2, 5, 10],\n",
            " 'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000]}\n",
            "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
            "Time elapsed:  31.588361024856567\n",
            "\n",
            "\n",
            "{'bootstrap': False,\n",
            " 'max_depth': 50,\n",
            " 'max_features': 'auto',\n",
            " 'min_samples_leaf': 2,\n",
            " 'min_samples_split': 2,\n",
            " 'n_estimators': 2000}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Grid Search CV for Gradient Boosting"
      ],
      "metadata": {
        "id": "YF5nL_HsdFr6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Number of features to consider at every split\n",
        "learning_rates = [1, 0.5, 0.25, 0.1, 0.05, 0.01]\n",
        "# Maximum number of levels in tree\n",
        "min_samples_splits = np.linspace(0.1, 1.0, 10, endpoint=True)\n",
        "max_depths = np.linspace(1, 32, 32, endpoint=True)\n",
        "n_estimators = [1, 2, 4, 8, 16, 32, 64, 100, 200]\n",
        "min_samples_leafs = np.linspace(0.1, 0.5, 5, endpoint=True)\n",
        "max_features = list(range(1,train_feature.shape[1]))\n",
        "# Minimum number of samples required at each leaf node\n",
        "\n",
        "# Create the random grid\n",
        "random_grid_grad = {'learning_rate': learning_rates,\n",
        "               'n_estimators': n_estimators,\n",
        "               'max_depth':max_depths,\n",
        "               'min_samples_split':min_samples_splits,\n",
        "               'min_samples_leaf':min_samples_leafs,\n",
        "               'max_features':max_features}\n",
        "\n",
        "pprint(random_grid_grad)\n",
        "\n",
        "# Use the random grid to search for best hyperparameters\n",
        "# First create the base model to tune\n",
        "gb = GradientBoostingClassifier()\n",
        "# Random search of parameters, using 3 fold cross validation, \n",
        "# search across 100 different combinations, and use all available cores\n",
        "gb_random = RandomizedSearchCV(estimator=gb, param_distributions=random_grid_grad,\n",
        "                              n_iter = 50, scoring='neg_mean_absolute_error', \n",
        "                              cv = 3, verbose=2, n_jobs=-1,\n",
        "                              return_train_score=True)\n",
        "\n",
        "# Fit the random search model\n",
        "gb_random.fit(train_feature, train_label);\n",
        "\n",
        "gb_random.best_params_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X_M_g_jDdFTB",
        "outputId": "256b18dd-f13b-4075-cd1c-3fab88214a4b"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'learning_rate': [1, 0.5, 0.25, 0.1, 0.05, 0.01],\n",
            " 'max_depth': array([ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13.,\n",
            "       14., 15., 16., 17., 18., 19., 20., 21., 22., 23., 24., 25., 26.,\n",
            "       27., 28., 29., 30., 31., 32.]),\n",
            " 'max_features': [1, 2, 3, 4, 5, 6, 7],\n",
            " 'min_samples_leaf': array([0.1, 0.2, 0.3, 0.4, 0.5]),\n",
            " 'min_samples_split': array([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1. ]),\n",
            " 'n_estimators': [1, 2, 4, 8, 16, 32, 64, 100, 200]}\n",
            "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'learning_rate': 0.25,\n",
              " 'max_depth': 18.0,\n",
              " 'max_features': 6,\n",
              " 'min_samples_leaf': 0.2,\n",
              " 'min_samples_split': 0.2,\n",
              " 'n_estimators': 100}"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fitting model using the parameters obtained from Grid Search CV"
      ],
      "metadata": {
        "id": "t8Q2x_7ldWwI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "models = [RandomForestClassifier(bootstrap=False,max_depth=None,max_features='sqrt',min_samples_leaf=1,min_samples_split=2,n_estimators=750,random_state=40),  \n",
        "          GradientBoostingClassifier(learning_rate=0.05,max_depth=24,max_features=6,min_samples_leaf=0.1,min_samples_split=2,n_estimators=100)]\n",
        "\n",
        "names = [\"Random Forest (parameters - Grid search CV)\",\"Gradient Boost Classifier (parameters - Grid search CV)\"]\n",
        "for model, name in zip(models, names):\n",
        "    print(name)\n",
        "    start = time.time()\n",
        "    for score in [\"accuracy\", \"precision\", \"recall\"]:\n",
        "        print(score,\" : \",cross_val_score(model, X, y ,scoring=score, cv=5).mean())\n",
        "       \n",
        "    print('Time elapsed: ',time.time() - start)\n",
        "    print('\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u4lZ3GIEdpn4",
        "outputId": "c9843574-a612-4c81-c305-3c14cd67320e"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest (parameters - Grid search CV)\n",
            "accuracy  :  0.868421052631579\n",
            "precision  :  0.8654015042824226\n",
            "recall  :  0.8736842105263157\n",
            "Time elapsed:  13.794224262237549\n",
            "\n",
            "\n",
            "Gradient Boost Classifier (parameters - Grid search CV)\n",
            "accuracy  :  0.8631578947368421\n",
            "precision  :  0.8911269791455092\n",
            "recall  :  0.8263157894736842\n",
            "Time elapsed:  1.2279579639434814\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fitting the Final Choosen model and getting the Confusion Matrix"
      ],
      "metadata": {
        "id": "rfbmDMGAdv3p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rf_final = RandomForestClassifier(bootstrap=False,max_depth=None,max_features='sqrt',min_samples_leaf=1,min_samples_split=2,n_estimators=750,random_state=40)\n",
        "rf_final.fit(train_feature, train_label)\n",
        "\n",
        "rf_final_predict = rf_final.predict(test_feature)\n",
        "\n",
        "print(\"=== Confusion Matrix ===\")\n",
        "print(confusion_matrix(test_label, rf_final_predict))\n",
        "print('\\n')\n",
        "print(\"=== Classification Report ===\")\n",
        "print(classification_report(test_label, rf_final_predict))"
      ],
      "metadata": {
        "id": "bsw1CYQUd1yo",
        "outputId": "1687f392-0226-49e4-9862-09162f0805e0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Confusion Matrix ===\n",
            "[[37  2]\n",
            " [ 3 34]]\n",
            "\n",
            "\n",
            "=== Classification Report ===\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.95      0.94        39\n",
            "           1       0.94      0.92      0.93        37\n",
            "\n",
            "    accuracy                           0.93        76\n",
            "   macro avg       0.93      0.93      0.93        76\n",
            "weighted avg       0.93      0.93      0.93        76\n",
            "\n"
          ]
        }
      ]
    }
  ]
}